{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1098e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gultekinqwe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gultekinqwe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# üìö Gerekli k√ºt√ºphaneleri y√ºkle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c78cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ √ñn i≈üleme fonksiyonu\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa21b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ √ñzellik √ßƒ±karƒ±mƒ± fonksiyonu\n",
    "def extract_features(df):\n",
    "    df[\"clean_text\"] = df[\"text\"].apply(preprocess)\n",
    "    df = df[df[\"clean_text\"].str.strip() != \"\"]\n",
    "    df = df[df[\"clean_text\"].str.len() > 3]\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_vectors = tfidf.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "    lsa = TruncatedSVD(n_components=100, random_state=42)\n",
    "    X_lsa = lsa.fit_transform(tfidf_vectors)\n",
    "\n",
    "    sentences = [text.split() for text in df[\"clean_text\"]]\n",
    "    w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2)\n",
    "    word_vectors = w2v_model.wv\n",
    "\n",
    "    kmeans = KMeans(n_clusters=50, random_state=42)\n",
    "    kmeans.fit(word_vectors.vectors.astype(np.float64))\n",
    "\n",
    "    def get_cluster_features(text):\n",
    "        cluster_count = np.zeros(50)\n",
    "        if not isinstance(text, str): return cluster_count\n",
    "        for word in text.split():\n",
    "            if word in word_vectors:\n",
    "                vec = np.asarray(word_vectors[word], dtype=np.float64)\n",
    "                idx = kmeans.predict([vec])[0]\n",
    "                cluster_count[idx] += 1\n",
    "        return cluster_count\n",
    "\n",
    "    semantic_vectors = np.array([get_cluster_features(text) for text in df[\"clean_text\"]])\n",
    "    X = np.hstack((X_lsa, semantic_vectors))\n",
    "    y = df[\"label\"].values\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f52e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Model eƒüitim ve deƒüerlendirme fonksiyonu\n",
    "def train_and_evaluate(X, y, dataset_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"MLP\": MLPClassifier(max_iter=300, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"SVM\": SVC(probability=True, random_state=42)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"\\n--- {dataset_name} | {name} ---\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4013cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5571, 2)\n",
      "(33345, 2)\n"
     ]
    }
   ],
   "source": [
    "# Veri setlerini oku\n",
    "df1 = pd.read_csv(\"dataFile/spam_modified.csv\", sep=';', header=0, usecols=[0, 1])\n",
    "df2 = pd.read_csv(\"dataFile/enron_spam_data_modified.csv\", sep=';', header=0, usecols=[0, 1])\n",
    "\n",
    "df1.columns = ['label', 'text']\n",
    "df2.columns = ['label', 'text']\n",
    "\n",
    "df1['label'] = df1['label'].str.strip().str.lower().map({'ham': 0, 'spam': 1})\n",
    "df2['label'] = df2['label'].str.strip().str.lower().map({'ham': 0, 'spam': 1})\n",
    "    \n",
    "df1.dropna(subset=['label', 'text'], inplace=True)\n",
    "df2.dropna(subset=['label', 'text'], inplace=True)\n",
    "\n",
    "df1['label'] = df1['label'].astype(int)\n",
    "df2['label'] = df2['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "155a3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Spam Modified Dataset | MLP ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       956\n",
      "           1       0.91      0.85      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1105\n",
      "   macro avg       0.95      0.92      0.93      1105\n",
      "weighted avg       0.97      0.97      0.97      1105\n",
      "\n",
      "Accuracy: 0.9692307692307692\n",
      "F1 Score: 0.8819444444444444\n",
      "ROC AUC: 0.9695038050040717\n",
      "\n",
      "--- Spam Modified Dataset | Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       956\n",
      "           1       0.98      0.80      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1105\n",
      "   macro avg       0.98      0.90      0.93      1105\n",
      "weighted avg       0.97      0.97      0.97      1105\n",
      "\n",
      "Accuracy: 0.9710407239819004\n",
      "F1 Score: 0.8814814814814815\n",
      "ROC AUC: 0.9752078009603774\n",
      "\n",
      "--- Spam Modified Dataset | SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       956\n",
      "           1       0.95      0.71      0.82       149\n",
      "\n",
      "    accuracy                           0.96      1105\n",
      "   macro avg       0.96      0.85      0.90      1105\n",
      "weighted avg       0.96      0.96      0.95      1105\n",
      "\n",
      "Accuracy: 0.9565610859728507\n",
      "F1 Score: 0.8153846153846154\n",
      "ROC AUC: 0.955098143831962\n",
      "\n",
      "--- Enron Dataset | MLP ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3296\n",
      "           1       0.98      0.99      0.98      3362\n",
      "\n",
      "    accuracy                           0.98      6658\n",
      "   macro avg       0.98      0.98      0.98      6658\n",
      "weighted avg       0.98      0.98      0.98      6658\n",
      "\n",
      "Accuracy: 0.9822769600480625\n",
      "F1 Score: 0.9825392127848476\n",
      "ROC AUC: 0.9954992044148477\n",
      "\n",
      "--- Enron Dataset | Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3296\n",
      "           1       0.98      0.99      0.98      3362\n",
      "\n",
      "    accuracy                           0.98      6658\n",
      "   macro avg       0.98      0.98      0.98      6658\n",
      "weighted avg       0.98      0.98      0.98      6658\n",
      "\n",
      "Accuracy: 0.9824271553018925\n",
      "F1 Score: 0.982730627306273\n",
      "ROC AUC: 0.9980621599631518\n",
      "\n",
      "--- Enron Dataset | SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      3296\n",
      "           1       0.94      0.95      0.94      3362\n",
      "\n",
      "    accuracy                           0.94      6658\n",
      "   macro avg       0.94      0.94      0.94      6658\n",
      "weighted avg       0.94      0.94      0.94      6658\n",
      "\n",
      "Accuracy: 0.9436767798137579\n",
      "F1 Score: 0.9445512346591749\n",
      "ROC AUC: 0.9803224430095354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# √ñzellik √ßƒ±kar ve eƒüit\n",
    "X1, y1 = extract_features(df1)\n",
    "train_and_evaluate(X1, y1, \"Spam Modified Dataset\")\n",
    "\n",
    "X2, y2 = extract_features(df2)\n",
    "train_and_evaluate(X2, y2, \"Enron Dataset\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
